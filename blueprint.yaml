tosca_definitions_version: cloudify_dsl_1_3

imports:
  - http://cloudify.co/spec/cloudify/5.0.0/types.yaml
  - plugin:cloudify-fabric-plugin

inputs:
  infra_blueprint:
    description: >
      Name of infrastructure blueprint to deploy.
    type: string
    constraints:
      - valid_values:
          - infra-openstack
          - infra-azure
          - infra-aws
          - infra-gcp
  infra_archive:
    description: >
      URL of infra zip file.
    type: string
    default: 'https://github.com/cloudify-community/blueprint-examples/releases/download/5.0.0-15/getting-started-infra.zip'
  infra_exists:
    description: >
      Whether a getting started infrastructure blueprint has already been uploaded to the manager or not.
    default: false

node_templates:
  # Represents the infrastructure.
  infrastructure:
    type: cloudify.nodes.Component
    properties:
      resource_config:
        blueprint:
          id: { get_input: infra_blueprint }
          blueprint_archive: { get_input: infra_archive }
          external_resource: { get_input: infra_exists }

  # Represents an application.
  app:
    type: cloudify.nodes.SoftwareComponent
    interfaces:
      # Standard lifecycle operations. Each one runs a script.
      # All scripts here run via the fabric plugin, in "script runner" mode:
      #
      # * The plugin code itself runs on the Manager (the default executor of
      #   the fabric plugin is "central_deployment_agent")
      # * The plugin operation establishes n SSH connection to the target,
      #   transfers the script, and executes it there.
      cloudify.interfaces.lifecycle:
        create:
          implementation: fabric.fabric_plugin.tasks.run_script
          inputs:
            script_path: scripts/app-create.sh
            # fabric_env tells Cloudify how to connect to the remote host
            # in order to run the script. We specify the host IP, the
            # SSH user to use, and the the path to the private key.
            # Note that since the plugin's code runs on the manager (as is
            # the default for the fabric plugin), the key_filename should point
            # to a file on the Manager.
            fabric_env: &fabric_env
              host_string: { get_capability: [ { get_attribute: [ infrastructure, deployment, id ] }, endpoint ]}
              user: { get_capability: [ { get_attribute: [ infrastructure, deployment, id ] }, user ]}
              key_filename: { get_capability: [ { get_attribute: [ infrastructure, deployment, id ] }, key_filename ]}
        delete:
          implementation: fabric.fabric_plugin.tasks.run_script
          inputs:
            script_path: scripts/app-delete.sh
            fabric_env: *fabric_env
      # Custom maintenance interface, containing custom operations.
      maintenance:
        update:
          implementation: fabric.fabric_plugin.tasks.run_script
          inputs:
            script_path: scripts/app-update.py
            fabric_env: *fabric_env
        commit:
          implementation: fabric.fabric_plugin.tasks.run_script
          inputs:
            script_path: scripts/app-commit.py
            fabric_env: *fabric_env
        poll:
          implementation: fabric.fabric_plugin.tasks.run_script
          inputs:
            script_path: scripts/app-poll.sh
            fabric_env: *fabric_env
    relationships:
      - target: infrastructure
        type: cloudify.relationships.depends_on

workflows:
  # Define a custom workflow called "rollout". The workflow is implemented as a
  # Python script.
  rollout:
    mapping: scripts/rollout.py
